---
title: "extravasation experiment analysis"
output: html_document
date: "2024-11-17"
---

#Analysis of trends from extravasation experiment
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, fig.align = 'center')
```
load libraries

```{r, message = FALSE}
library(RSQLite)
library(dbplyr)
library(dplyr)
library(purrr)
library(ggplot2)
library(xts)
library(ggfortify)
library(ggthemes)
library(maps)
library(mapdata)
library(leaflet)
library(remotes)
library(qst)
library(ymd)
library(tidyverse)
library(emmeans)
library(ggplot2)
library("readxl")

```

#Load data
```{r}

mydata=read_excel("C:/R/Resources/SplitData.xlsx")

#take a look at the data
glimpse(mydata)

#split data based on experiment index
df1 <- mydata[mydata$experiment == 1, ]
df2 <- mydata[mydata$experiment == 2, ]
df3 <- mydata[mydata$experiment == 3, ]
df4 <- mydata[mydata$experiment == 4, ]
df5 <- mydata[mydata$experiment == 5, ]


#take a look at the data
glimpse(df1)
glimpse(df2)
glimpse(df3)
glimpse(df4)
glimpse(df5)


#further split data based on condition
df1_2 <- df1[df1$condition == 2, ]
df1_4 <- df1[df1$condition == 4, ]
df1_6 <- df1[df1$condition == 6, ]

df2_2 <- df2[df2$condition == 2, ]
df2_4 <- df2[df2$condition == 4, ]
df2_6 <- df2[df2$condition == 6, ]

df3_2 <- df3[df3$condition == 2, ]
df3_4 <- df3[df3$condition == 4, ]
df3_6 <- df3[df3$condition == 6, ]

df4_2 <- df4[df4$condition == 2, ]
df4_4 <- df4[df4$condition == 4, ]
df4_6 <- df4[df4$condition == 6, ]

df5_2 <- df5[df5$condition == 2, ]
df5_4 <- df5[df5$condition == 4, ]
df5_6 <- df5[df5$condition == 6, ]


#take a look at the data
glimpse(df1_2)
glimpse(df1_4)
glimpse(df1_6)

glimpse(df2_2)
glimpse(df2_4)
glimpse(df2_6)

glimpse(df3_2)
glimpse(df3_4)
glimpse(df3_6)

glimpse(df4_2)
glimpse(df4_4)
glimpse(df4_6)

glimpse(df5_2)
glimpse(df5_4)
glimpse(df5_6)


```

#Analyze some basic trends. Look at count by time, and by condition
```{r}
#entire data set grouped by time
mydata %>% 
    group_by(time) %>%
    ggplot(aes(x = time, y = count)) + 
    geom_bar(stat = 'identity', fill = 'orange') +
    geom_smooth(method = 'lm', se = FALSE, linetype = 'dashed', size = 0.4, color = 'red') + 
    labs(x = '', y = 'Count', title = 'Count by Time')

#each experiment separately grouped by time
df1 %>% 
    group_by(time) %>%
    ggplot(aes(x = time, y = count/nrow(df1))) + 
    geom_bar(stat = 'identity', fill = 'orange') +
    geom_smooth(method = 'lm', se = FALSE, linetype = 'dashed', size = 0.4, color = 'red') + 
    labs(x = '', y = 'Count', title = 'Count by Time - Experiment 1')
df2 %>% 
    group_by(time) %>%
    ggplot(aes(x = time, y = count/nrow(df2))) + 
    geom_bar(stat = 'identity', fill = 'orange') +
    geom_smooth(method = 'lm', se = FALSE, linetype = 'dashed', size = 0.4, color = 'red') + 
    labs(x = '', y = 'Count', title = 'Count by Time - Experiment 2')
df3 %>% 
    group_by(time) %>%
    ggplot(aes(x = time, y = count/nrow(df3))) + 
    geom_bar(stat = 'identity', fill = 'orange') +
    geom_smooth(method = 'lm', se = FALSE, linetype = 'dashed', size = 0.4, color = 'red') + 
    labs(x = '', y = 'Count', title = 'Count by Time - Experiment 3')
df4 %>% 
    group_by(time) %>%
    ggplot(aes(x = time, y = count/nrow(df4))) + 
    geom_bar(stat = 'identity', fill = 'orange') +
    geom_smooth(method = 'lm', se = FALSE, linetype = 'dashed', size = 0.4, color = 'red') + 
    labs(x = '', y = 'Count', title = 'Count by Time - Experiment 4')
df5 %>% 
    group_by(time) %>%
    ggplot(aes(x = time, y = count/nrow(df5))) + 
    geom_bar(stat = 'identity', fill = 'orange') +
    geom_smooth(method = 'lm', se = FALSE, linetype = 'dashed', size = 0.4, color = 'red') + 
    labs(x = '', y = 'Count', title = 'Count by Time - Experiment 5')


```

```{r}

```


```{r}
#entire data set grouped by condition
mydata %>% 
    group_by(condition) %>%
    ggplot(aes(x = condition, y = count)) + 
    geom_bar(stat = 'identity', fill = 'orange') +
    geom_smooth(method = 'lm', se = FALSE, linetype = 'dashed', size = 0.4, color = 'red') + 
    labs(x = '', y = 'Count', title = 'Count by Condition')

#each experiment separately grouped by condition
df1 %>% 
    group_by(condition) %>%
    ggplot(aes(x = condition, y = count/nrow(df1))) + 
    geom_bar(stat = 'identity', fill = 'orange') +
    geom_smooth(method = 'lm', se = FALSE, linetype = 'dashed', size = 0.4, color = 'red') + 
    labs(x = '', y = 'Count', title = 'Count by Condition - Experiment 1')
df2 %>% 
    group_by(condition) %>%
    ggplot(aes(x = condition, y = count/nrow(df2))) + 
    geom_bar(stat = 'identity', fill = 'orange') +
    geom_smooth(method = 'lm', se = FALSE, linetype = 'dashed', size = 0.4, color = 'red') + 
    labs(x = '', y = 'Count', title = 'Count by Condition - Experiment 2')
df3 %>% 
    group_by(condition) %>%
    ggplot(aes(x = condition, y = count/nrow(df3))) + 
    geom_bar(stat = 'identity', fill = 'orange') +
    geom_smooth(method = 'lm', se = FALSE, linetype = 'dashed', size = 0.4, color = 'red') + 
    labs(x = '', y = 'Count', title = 'Count by Condition - Experiment 3')
df4 %>% 
    group_by(condition) %>%
    ggplot(aes(x = condition, y = count/nrow(df4))) + 
    geom_bar(stat = 'identity', fill = 'orange') +
    geom_smooth(method = 'lm', se = FALSE, linetype = 'dashed', size = 0.4, color = 'red') + 
    labs(x = '', y = 'Count', title = 'Count by Condition - Experiment 4')
df5 %>% 
    group_by(condition) %>%
    ggplot(aes(x = condition, y = count/nrow(df5))) + 
    geom_bar(stat = 'identity', fill = 'orange') +
    geom_smooth(method = 'lm', se = FALSE, linetype = 'dashed', size = 0.4, color = 'red') + 
    labs(x = '', y = 'Count', title = 'Count by Condition - Experiment 5')




```

```{r}
#each experiment and condition separately (vs time)
df1_2 %>% 
    group_by(time) %>%
    ggplot(aes(x = time, y = count/nrow(df1_2))) + 
    geom_bar(stat = 'identity', fill = 'orange') +
    geom_smooth(method = 'lm', se = FALSE, linetype = 'dashed', size = 0.4, color = 'red') + 
    labs(x = '', y = 'Count', title = 'Count by Time - Experiment 1, Condition 2')
df1_4 %>% 
    group_by(time) %>%
    ggplot(aes(x = time, y = count/nrow(df1_4))) + 
    geom_bar(stat = 'identity', fill = 'orange') +
    geom_smooth(method = 'lm', se = FALSE, linetype = 'dashed', size = 0.4, color = 'red') + 
    labs(x = '', y = 'Count', title = 'Count by Time - Experiment 1, Condition 4')
df1_6 %>% 
    group_by(time) %>%
    ggplot(aes(x = time, y = count/nrow(df1_6))) + 
    geom_bar(stat = 'identity', fill = 'orange') +
    geom_smooth(method = 'lm', se = FALSE, linetype = 'dashed', size = 0.4, color = 'red') + 
    labs(x = '', y = 'Count', title = 'Count by Time - Experiment 1, Condition 6')

df2_2 %>% 
    group_by(time) %>%
    ggplot(aes(x = time, y = count/nrow(df2_2))) + 
    geom_bar(stat = 'identity', fill = 'orange') +
    geom_smooth(method = 'lm', se = FALSE, linetype = 'dashed', size = 0.4, color = 'red') + 
    labs(x = '', y = 'Count', title = 'Count by Time - Experiment 2, Condition 2')
df2_4 %>% 
    group_by(time) %>%
    ggplot(aes(x = time, y = count/nrow(df2_4))) + 
    geom_bar(stat = 'identity', fill = 'orange') +
    geom_smooth(method = 'lm', se = FALSE, linetype = 'dashed', size = 0.4, color = 'red') + 
    labs(x = '', y = 'Count', title = 'Count by Time - Experiment 2, Condition 4')
df2_6 %>% 
    group_by(time) %>%
    ggplot(aes(x = time, y = count/nrow(df2_6))) + 
    geom_bar(stat = 'identity', fill = 'orange') +
    geom_smooth(method = 'lm', se = FALSE, linetype = 'dashed', size = 0.4, color = 'red') + 
    labs(x = '', y = 'Count', title = 'Count by Time - Experiment 2, Condition 6')

df3_2 %>% 
    group_by(time) %>%
    ggplot(aes(x = time, y = count/nrow(df3_2))) + 
    geom_bar(stat = 'identity', fill = 'orange') +
    geom_smooth(method = 'lm', se = FALSE, linetype = 'dashed', size = 0.4, color = 'red') + 
    labs(x = '', y = 'Count', title = 'Count by Time - Experiment 3, Condition 2')
df3_4 %>% 
    group_by(time) %>%
    ggplot(aes(x = time, y = count/nrow(df3_4))) + 
    geom_bar(stat = 'identity', fill = 'orange') +
    geom_smooth(method = 'lm', se = FALSE, linetype = 'dashed', size = 0.4, color = 'red') + 
    labs(x = '', y = 'Count', title = 'Count by Time - Experiment 3, Condition 4')
df3_6 %>% 
    group_by(time) %>%
    ggplot(aes(x = time, y = count/nrow(df3_6))) + 
    geom_bar(stat = 'identity', fill = 'orange') +
    geom_smooth(method = 'lm', se = FALSE, linetype = 'dashed', size = 0.4, color = 'red') + 
    labs(x = '', y = 'Count', title = 'Count by Time - Experiment 3, Condition 6')

df4_2 %>% 
    group_by(time) %>%
    ggplot(aes(x = time, y = count/nrow(df4_2))) + 
    geom_bar(stat = 'identity', fill = 'orange') +
    geom_smooth(method = 'lm', se = FALSE, linetype = 'dashed', size = 0.4, color = 'red') + 
    labs(x = '', y = 'Count', title = 'Count by Time - Experiment 4, Condition 2')
df4_4 %>% 
    group_by(time) %>%
    ggplot(aes(x = time, y = count/nrow(df4_4))) + 
    geom_bar(stat = 'identity', fill = 'orange') +
    geom_smooth(method = 'lm', se = FALSE, linetype = 'dashed', size = 0.4, color = 'red') + 
    labs(x = '', y = 'Count', title = 'Count by Time - Experiment 4, Condition 4')
df4_6 %>% 
    group_by(time) %>%
    ggplot(aes(x = time, y = count/nrow(df4_6))) + 
    geom_bar(stat = 'identity', fill = 'orange') +
    geom_smooth(method = 'lm', se = FALSE, linetype = 'dashed', size = 0.4, color = 'red') + 
    labs(x = '', y = 'Count', title = 'Count by Time - Experiment 4, Condition 6')

df5_2 %>% 
    group_by(time) %>%
    ggplot(aes(x = time, y = count/nrow(df5_2))) + 
    geom_bar(stat = 'identity', fill = 'orange') +
    geom_smooth(method = 'lm', se = FALSE, linetype = 'dashed', size = 0.4, color = 'red') + 
    labs(x = '', y = 'Count', title = 'Count by Time - Experiment 5, Condition 2')
df5_4 %>% 
    group_by(time) %>%
    ggplot(aes(x = time, y = count/nrow(df5_4))) + 
    geom_bar(stat = 'identity', fill = 'orange') +
    geom_smooth(method = 'lm', se = FALSE, linetype = 'dashed', size = 0.4, color = 'red') + 
    labs(x = '', y = 'Count', title = 'Count by Time - Experiment 5, Condition 4')
df5_6 %>% 
    group_by(time) %>%
    ggplot(aes(x = time, y = count/nrow(df5_6))) + 
    geom_bar(stat = 'identity', fill = 'orange') +
    geom_smooth(method = 'lm', se = FALSE, linetype = 'dashed', size = 0.4, color = 'red') + 
    labs(x = '', y = 'Count', title = 'Count by Time - Experiment 5, Condition 6')



#something going on with experiment 2, all three conditions are outliers compared to other experiments

```



#plot count against each factor to inspect individual relationships
```{r}
#count vs. experiment
plot(mydata$experiment,mydata$count,xlab="experiment",pch=20,ylab="count", ylim=c(0,2.5),xlim=c(0,5))

#count vs. condition
plot(mydata$condition,mydata$count,xlab="condition",pch=20,ylab="count", ylim=c(0,2.5),xlim=c(0,10))

#count vs. time
plot(mydata$time,mydata$count,xlab="time",pch=20,ylab="count", ylim=c(0,2.5),xlim=c(0,10))


#range of counts shows lot of variability for each experiment, especially big range by time. Why are neutrophil concentrations showing big range after 8 hours? 
```

#run simple linear regression analysis
#full model with all experiments
######################################################################################

```{r}
#full model with all experiments
experiment=as.factor(mydata$experiment) 
condition=as.factor(mydata$condition) 
time = mydata$time #time is a continuous variable
count=mydata$count
fit = lm(count~ experiment+condition+time)
plot(fit)
summary(fit)

#Regression analysis: experiments 2 and 5 are not statistically different from experiment 1
# conditions 4 and 6 are statistically different from condition 2
# the model is linear with respect to time (statistically significant)
# intercept is not statistically significant
#observations 132, 476 have high residuals (likely outliers)

#Look for outliers
#########################################
#Compute Studentized residuals
resstudent <- rstudent(fit)
#Plot Studentized residuals
plot (resstudent, ylab="Studentized Residuals")
abline (h=0)
#test Studentized residuals (observation #476 detected as an outlier)
car::outlierTest(fit, n.max = Inf)


#Look for potentially influential points
#########################################
#compute and inspect Cook's statistics
cook <- cooks.distance (fit)
cook
library(ggplot2)
library(faraway)
halfnorm (cook, 3, ylab="Cook's distances")

#point 476 with the largest Cook's distance is indicated as the most influential



#Look for leverage points
#########################################
#compute the leverage value for all the observations
leverage = hatvalues(fit)

#plot leverage values
plot(leverage)

library(car)

#plot residuals, leverage, and Cook's distance 
influencePlot(fit)

# point 476 is being identified as high leverage point


#exclude point 476 with the largest Cook's distance and therefore the most influential and re-fit the data
fit_minus_476 <- lm (count ~ experiment+condition+time,mydata, subset=(cook < max (cook)))
summary (fit_minus_476)

#compare with fitting the full dataset
fit_full = lm(count~ experiment+condition+time, mydata)
summary (fit_full)

#the model with point 476 removed produces worse fit than the full model as evidenced by:
# 1. smaller R-squared value
# 2. lower F-statistic

```

```{r}
#full model with all experiments
experiment=as.factor(mydata$experiment)
condition=as.factor(mydata$condition)
time = mydata$time #time is a continuous variable
count=mydata$count
fit = lm(count~ experiment+condition+time)

#Look for violations of Constant Variance
#########################################

#plot all residuals
plot (fitted (fit), residuals (fit), xlab="Fitted", ylab="Residuals")
abline (h=0)
plot (fitted (fit), abs (residuals (fit)),
xlab="Fitted", ylab="|Residuals|")

#plot residuals against individual predictors on one plot side-by-side and absolute values on four individual plots
car::residualPlots(fit, pch=20, col="red", fitted = F, ask = F, layout = c(3,2), tests = F, quadratic = F)
plot (experiment, abs(residuals (fit)), xlab="experiment", ylab="}|Residuals|")
plot (condition, abs(residuals (fit)), xlab="condition", ylab="}|Residuals|")
plot (time, abs(residuals (fit)), xlab="time", ylab="}|Residuals|")

#residuals are seen positively correlated to fitted values
#no significant difference detected by variance test
#large residuals detected in experiment 2 and 5



#Look for violations of Normality
#########################################
res <- fit$residuals
#histogram of residuals
hist(res, xlab = "Residuals", probability = T, ylim = c(0, 6))
#empirical density
lines(density(res, na.rm=T), lwd = 2, col = "red")
#best fitting normal curve
curve(dnorm(x, mean = mean(res, na.rm=T), sd = sd(res, na.rm=T)), lty = 2, lwd = 2, add = TRUE, col = "blue")
#no deviation from Normality seen

#ordered values of the residuals vs quantiles of the standard normal distribution (Q-Q plot)
qqnorm(as.numeric(res), col="red", pch=20)
qqline(as.numeric(res), col="blue", lty=1, lwd=1)
#deviation from standard normal distribution seen in the bottom quantile

#The Shapiro-Wilk test 
shapiro.test (residuals (fit))
#violation of Normality detected


#Look for violations of Linearity
#########################################
#generate component-plus-residual plot for each predictor
car::crPlots(fit, terms = . ~ experiment+condition+time, pch=20, col="red")
#experiment 1, 2, and 5 are distinct from 3 and 4
#very small deviation from linearity seen for time


#Look for Correlations
#########################################
#make an index plot of the residuals. Look for longer runs of residuals above or below the line.
plot (residuals (fit), ylab="Residuals")
abline (h=0)
#some correlation seen in individual experiments

#check for correlation using a regression of successive residuals
summary(lm(residuals(fit)[-1] ~ 1+residuals (fit) [-1]))
#no significant correlation seen

#compute the Durbin-Watson statistic
library(lmtest)
dwtest (count ~ experiment+condition+time, data=mydata)
#significant correlation seen


#outliers in Pearson residual plot in experiment 2, 5, and condition 2
#no indications of non-normatility in histogram of residuals 
#Normal Q-Q plot shows points in the lowest quantile that slightly deviate from normality 
#shapiro-wilk normality test shows deviation from normality 
#durban watson test shows that there is correlation between experiment, condition and time 

```

# Re-run with experiments 1, 2, and 5
#####################################################################

```{r}
#for experiments 1, 2, 5
updated <- rbind(df1, df2, df5)
experiment=as.factor(updated$experiment)
condition=as.factor(updated$condition)
time = updated$time #time is a continuous variable
count=updated$count
fit = lm(count~ experiment+condition+time)
plot(fit)
summary(fit)

#Quick analysis: experiments 2 and 5 are not statistically different from experiment 1
# condition 4 is not statistically different from condition 2, but just barely above the significance threshold of 0.05 so nothing to do here
# the model is linear with respect to time (statistically significant)
# intercept is statistically significant
# observations 132, 263, 278 have high residuals (likely outliers) and are also high leverage points and/or have large Cook's distance


#Look for outliers
#########################################
#Compute Studentized residuals
resstudent <- rstudent(fit)
#Plot Studentized residuals
plot (resstudent, ylab="Studentized Residuals")
abline (h=0)
#test Studentized residuals (observations #132, #235 and #278 detected as outliers)
car::outlierTest(fit, n.max = Inf)


#Look for potentially influential points
#########################################
#compute and inspect Cook's statistics
cook <- cooks.distance (fit)
cook
library(ggplot2)
library(faraway)
halfnorm (cook, 3, ylab="Cook's distances")

#point 278 with the largest Cook's distance is indicated as the most influential



#Look for leverage points
#########################################
#compute the leverage value for all the observations
leverage = hatvalues(fit)

#plot leverage values
plot(leverage)

library(car)

#plot residuals, leverage, and Cook's distance 
influencePlot(fit)

# point 278 is being identified as high leverage point


#exclude point 278 with the largest Cook's distance and therefore the most influential and re-fit the data
fit_minus_278 <- lm (count ~ experiment+condition+time,updated, subset=(cook < max (cook)))
summary (fit_minus_278)

#compare with fitting the full dataset
fit_full = lm(count~ experiment+condition+time, updated)
summary (fit_full)



#exclude point 132, 235, 278 with the largest studentized residuals and large Cook's distances and re-fit the data
fit_minus_132_235_278 <- lm (count ~ experiment+condition+time,updated, subset=(resstudent < (max (resstudent)-0.7)))
summary (fit_minus_132_235_278)


#In both cases the model with points indicated as outliers removed produces worse fit than the full model as evidenced by:
# 1. smaller R-squared value
# 2. lower F-statistic

```



```{r}
#for experiments 1, 2, 5
updated <- rbind(df1, df2, df5)
experiment=as.factor(updated$experiment)
condition=as.factor(updated$condition)
time = updated$time #time is a continuous variable
count=updated$count
fit = lm(count~ experiment+condition+time)
plot(fit)
summary(fit)



#Look for violations of Constant Variance
#########################################

#plot all residuals
plot (fitted (fit), residuals (fit), xlab="Fitted", ylab="Residuals")
abline (h=0)
plot (fitted (fit), abs (residuals (fit)),
xlab="Fitted", ylab="|Residuals|")

#plot residuals against individual predictors on one plot side-by-side and absolute values on four individual plots
car::residualPlots(fit, pch=20, col="red", fitted = F, ask = F, layout = c(3,2), tests = F, quadratic = F)
plot (experiment, abs(residuals (fit)), xlab="experiment", ylab="}|Residuals|")
plot (condition, abs(residuals (fit)), xlab="condition", ylab="}|Residuals|")
plot (time, abs(residuals (fit)), xlab="time", ylab="}|Residuals|")

#residuals are seen positively correlated to fitted values
#no significant difference detected by variance test indicating constant variance
#large residuals detected in experiment 2 and 5



#Look for violations of Normality
#########################################
res <- fit$residuals
#histogram of residuals
hist(res, xlab = "Residuals", probability = T, ylim = c(0, 6))
#empirical density
lines(density(res, na.rm=T), lwd = 2, col = "red")
#best fitting normal curve
curve(dnorm(x, mean = mean(res, na.rm=T), sd = sd(res, na.rm=T)), lty = 2, lwd = 2, add = TRUE, col = "blue")
#deviation from Normality seen

#ordered values of the residuals vs quantiles of the standard normal distribution (Q-Q plot)
qqnorm(as.numeric(res), col="red", pch=20)
qqline(as.numeric(res), col="blue", lty=1, lwd=1)
#deviation from standard normal distribution seen in the top and the bottom quantiles

#The Shapiro-Wilk test 
shapiro.test (residuals (fit))
#significant violation of Normality detected


#Look for violations of Linearity
#########################################
#generate component-plus-residual plot for each predictor
car::crPlots(fit, terms = . ~ experiment+condition+time, pch=20, col="red")
#very small deviation from linearity seen for time


#Look for Correlations
#########################################
#make an index plot of the residuals. Look for longer runs of residuals above or below the line.
plot (residuals (fit), ylab="Residuals")
abline (h=0)
#some correlation seen in individual experiments

#check for correlation using a regression of successive residuals
summary(lm(residuals(fit)[-1] ~ 1+residuals (fit) [-1]))
#no significant correlation seen

#compute the Durbin-Watson statistic
library(lmtest)
dwtest (count ~ experiment+condition+time, data=updated)
#significant correlation seen


```



# Re-run with experiments 3 and 4
#####################################################################
```{r}
#for experiments 3 and 4
updated <- rbind(df3, df4)
experiment=as.factor(updated$experiment)
condition=as.factor(updated$condition)
time = updated$time #time is a continuous variable
count=updated$count
fit1 = lm(count~ experiment+condition+time)
par(mfrow=c(2,2))
plot(fit1)
summary(fit1)d

#grouping experiments 3 and 4 produces a better fit than grouping experiments 1,2,5
```
#Quick analysis: experiment 4 is statistically different from experiment 3 (should analyze them separately)
# condition 4 is statistically different from condition 2, but just barely below the significance threshold of 0.05 so nothing to do here
# the model is linear with respect to time (statistically significant)
# intercept is statistically siginificant
#observations 92, 95, 198 have high residuals (likely outliers) and are also high levarage points (should be removed)

# Re-run with experiments 3 and 4 separately
```{r}

#experiment 3
condition=as.factor(df3$condition)
time = df3$time
count=df3$count
fit_df3 = lm(count~condition+time)
par(mfrow=c(2,2))
plot(fit_df3)
summary(fit_df3)

#experiment 4
condition=as.factor(df4$condition)
time = df4$time
count=df4$count
fit_df4 = lm(count~condition+time)
par(mfrow=c(2,2))
plot(fit_df4)
summary(fit_df4)
```
#Quick analysis of experiment 3:
# conditions 4 and 6 are statistically different from condition 2
# the model is linear with respect to time (statistically significant)
# intercept is statistically siginificant
# observations 92, 95 have high residuals (likely outliers) and are also high levarage points and/or have large Cook's distance (should be removed)


#Quick analysis of experiment 4:
# condition 4 is not statistically different from condition 2
# the model is linear with respect to time (statistically significant)
# intercept is statistically siginificant
# observations 92, 95 have high residuals (likely outliers) and are also high levarage points and/or have large Cook's distance (should be removed)


```{r}
#each remaining experiment one at a time (1, 2 and 5)
#####################################################

#experiment 1
condition=as.factor(df1$condition)
time = df1$time
count=df1$count
fit_df1 = lm(count~condition+time)
par(mfrow=c(2,2))
plot(fit_df1)
summary(fit_df1)

#experiment 2
condition=as.factor(df2$condition)
time = df2$time
count=df2$count
fit_df2 = lm(count~condition+time)
par(mfrow=c(2,2))
plot(fit_df2)
summary(fit_df2)

#experiment 5
condition=as.factor(df5$condition)
time = df5$time
count=df5$count
fit_df5 = lm(count~condition+time)
par(mfrow=c(2,2))
plot(fit_df5)
summary(fit_df5)
```
#Quick analysis of experiment 1:
# condition 6 is not statistically different from condition 2
# the model is linear with respect to time (statistically significant)
# intercept is not statistically siginificant
# observations 47, 50 have high residuals (likely outliers) and are also high levarage points and/or have large Cook's distance (should be removed)

#Quick analysis of experiment 2:
# conditions 4 and 6 are statistically different from condition 2
# the model is linear with respect to time (statistically significant)
# intercept is statistically siginificant
# observations 91, 51, 61 have high residuals (likely outliers) and are also high levarage points and/or have large Cook's distance (should be removed)

#Quick analysis of experiment 5:
# conditions 4 and 6 are statistically different from condition 2
# the model is linear with respect to time (statistically significant)
# intercept is not statistically siginificant
# observations 92, 107 have high residuals (likely outliers) and are also high levarage points and/or have large Cook's distance (should be removed)


##################################################################
#Experiment with different variance models in GLS (equal variance)
##################################################################
```{r}
library(nlme)
experiment=as.factor(mydata$experiment)
condition=as.factor(mydata$condition)
count = mydata$count
time = mydata$time

fit3 = nlme::gls(count ~ experiment+condition+time, data = mydata)
par(mfrow=c(2,2))
plot(fit3)
summary(fit3)
```
#Experiment with different varaince models in GLS (ln time with equal variance)
```{r}
library(nlme)
experiment=as.factor(mydata$experiment)
condition=as.factor(mydata$condition)
count = mydata$count
lntime = mydata$lntimeadj
#fit3 = nlme::gls(count ~ experiment+condition:time, data = mydata,
#          weights = varIdent(form = ~1 | condition:experiment))
fit3 = nlme::gls(count ~ experiment+condition+lntime, data = mydata)
par(mfrow=c(2,2))
plot(fit3)
summary(fit3)
```
#Experiment with different varaince models in GLS (ln count and ln time with equal variance)
```{r}
library(nlme)
experiment=as.factor(mydata$experiment)
condition=as.factor(mydata$condition)
lncount = mydata$lncountadj
lntime = mydata$lntimeadj
#fit3 = nlme::gls(count ~ experiment+condition:time, data = mydata,
#          weights = varIdent(form = ~1 | condition:experiment))
fit3 = nlme::gls(lncount ~ experiment+condition+lntime, data = mydata)
par(mfrow=c(2,2))
plot(fit3)
summary(fit3)
```


#Experiment with different variance models in GLS (Exp variance)
```{r}
library(nlme)
experiment=as.factor(mydata$experiment)
condition=as.factor(mydata$condition)
count = mydata$count
time = mydata$time
fit3 <- gls(count ~ experiment+condition+time,  weights = varExp(form = ~ fitted(.)), data = mydata)
par(mfrow=c(2,2))
plot(fit3)
summary(fit3)
```


#Experiment with different variance models in GLS (ln count and ln time with Exp variance)
```{r}
experiment=as.factor(mydata$experiment)
condition=as.factor(mydata$condition)
lncount = mydata$lncountadj
lntime = mydata$lntimeadj
fit3 <- gls(lncount ~ experiment+condition+lntime,  weights = varExp(form = ~ fitted(.)), data = mydata)
par(mfrow=c(2,2))
plot(fit3)
summary(fit3)

```


# Analysis: 
# 1. Exponential variance model effectively deals with the dependency of residuals on fitted values
# 2. Ln transformation of time and count with the exponential variance model produces the best fit based on the AIC and BIC measures
# 3. The resulting model is linear in all three variables (experiment, condition, time) and all coefficients are statistically significant (intercept is not)


